{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFF0U3EXGt5CRz6kJZ+wrx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [  
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leslyndizeye/mental-health-chatbot/blob/main/Copy_of_Complete_Mental_Health_Counseling_Chatbot_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mental Health Support Chatbot**"
      ],
      "metadata": {
        "id": "CITi4gnxJObt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing All Required Libraries**"
      ],
      "metadata": {
        "id": "s9h3Wal8qbun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    GPT2Tokenizer,\n",
        "    GPT2LMHeadModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    pipeline\n",
        ")\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\" All libraries imported!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Sx4r7kqe3-",
        "outputId": "5e982259-19fc-42c5-e84e-05076c187b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported!\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading Dataset and Add Comprehensive**"
      ],
      "metadata": {
        "id": "XYWzZqTdqlsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Downloading mental health counseling dataset...\")\n",
        "\n",
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "print(f\" Dataset loaded: {len(df)} conversations\")\n",
        "\n",
        "# Comprehensive greetings in multiple languages with SHORT responses\n",
        "greetings_base = [\n",
        "    # English greetings\n",
        "    {\"patient\": \"Hello\", \"therapist\": \"Hello! I'm here to support you. How can I help you today?\"},\n",
        "    {\"patient\": \"Hi\", \"therapist\": \"Hi! I'm your mental health support assistant. What's on your mind?\"},\n",
        "    {\"patient\": \"Hey\", \"therapist\": \"Hey! I'm here to listen. How are you feeling?\"},\n",
        "    {\"patient\": \"Good morning\", \"therapist\": \"Good morning! How can I support you today?\"},\n",
        "    {\"patient\": \"Good afternoon\", \"therapist\": \"Good afternoon! I'm here to help. What's going on?\"},\n",
        "    {\"patient\": \"Good evening\", \"therapist\": \"Good evening! How are you feeling today?\"},\n",
        "    {\"patient\": \"Good night\", \"therapist\": \"Good night! Is there something on your mind?\"},\n",
        "    {\"patient\": \"How are you?\", \"therapist\": \"I'm here for you. How are you doing?\"},\n",
        "    {\"patient\": \"How are you doing?\", \"therapist\": \"I'm well, thank you. How about you?\"},\n",
        "    {\"patient\": \"What's up?\", \"therapist\": \"I'm here to help. What's on your mind?\"},\n",
        "    {\"patient\": \"Howdy\", \"therapist\": \"Hello! How can I support you today?\"},\n",
        "    {\"patient\": \"Greetings\", \"therapist\": \"Greetings! I'm here to listen. How are you?\"},\n",
        "\n",
        "    # Spanish\n",
        "    {\"patient\": \"Hola\", \"therapist\": \"Hola! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Buenos días\", \"therapist\": \"Good morning! How are you feeling today?\"},\n",
        "    {\"patient\": \"Buenas tardes\", \"therapist\": \"Good afternoon! I'm here to help. What's on your mind?\"},\n",
        "    {\"patient\": \"Buenas noches\", \"therapist\": \"Good evening! How can I support you?\"},\n",
        "    {\"patient\": \"¿Cómo estás?\", \"therapist\": \"I'm here for you. How are you doing?\"},\n",
        "\n",
        "    # French\n",
        "    {\"patient\": \"Bonjour\", \"therapist\": \"Bonjour! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Salut\", \"therapist\": \"Hello! I'm here to listen. What's on your mind?\"},\n",
        "    {\"patient\": \"Bonsoir\", \"therapist\": \"Good evening! How are you feeling today?\"},\n",
        "    {\"patient\": \"Comment allez-vous?\", \"therapist\": \"I'm here for you. How are you doing?\"},\n",
        "\n",
        "    # German\n",
        "    {\"patient\": \"Hallo\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Guten Morgen\", \"therapist\": \"Good morning! How are you feeling today?\"},\n",
        "    {\"patient\": \"Guten Tag\", \"therapist\": \"Good day! I'm here to help. What's on your mind?\"},\n",
        "    {\"patient\": \"Guten Abend\", \"therapist\": \"Good evening! How can I support you?\"},\n",
        "    {\"patient\": \"Wie geht es dir?\", \"therapist\": \"I'm here for you. How are you doing?\"},\n",
        "\n",
        "    # Italian\n",
        "    {\"patient\": \"Ciao\", \"therapist\": \"Ciao! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Buongiorno\", \"therapist\": \"Good morning! How are you feeling today?\"},\n",
        "    {\"patient\": \"Buonasera\", \"therapist\": \"Good evening! I'm here to help. What's on your mind?\"},\n",
        "    {\"patient\": \"Come stai?\", \"therapist\": \"I'm here for you. How are you doing?\"},\n",
        "\n",
        "    # Portuguese\n",
        "    {\"patient\": \"Olá\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Oi\", \"therapist\": \"Hi! I'm here to listen. What's on your mind?\"},\n",
        "    {\"patient\": \"Bom dia\", \"therapist\": \"Good morning! How are you feeling today?\"},\n",
        "    {\"patient\": \"Boa tarde\", \"therapist\": \"Good afternoon! How can I support you?\"},\n",
        "    {\"patient\": \"Boa noite\", \"therapist\": \"Good evening! I'm here to help. What's going on?\"},\n",
        "\n",
        "    # Hindi\n",
        "    {\"patient\": \"Namaste\", \"therapist\": \"Namaste! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Namaskar\", \"therapist\": \"Hello! I'm here to listen. How are you feeling?\"},\n",
        "\n",
        "    # Arabic\n",
        "    {\"patient\": \"Marhaba\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Salam\", \"therapist\": \"Peace be with you. I'm here to listen. What's on your mind?\"},\n",
        "\n",
        "    # Chinese\n",
        "    {\"patient\": \"Nǐ hǎo\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"你好\", \"therapist\": \"Hello! I'm here to listen. How are you feeling?\"},\n",
        "\n",
        "    # Japanese\n",
        "    {\"patient\": \"Konnichiwa\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Ohayou\", \"therapist\": \"Good morning! How are you feeling today?\"},\n",
        "\n",
        "    # Korean\n",
        "    {\"patient\": \"Annyeong\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"안녕하세요\", \"therapist\": \"Hello! I'm here to listen. What's on your mind?\"},\n",
        "\n",
        "    # Russian\n",
        "    {\"patient\": \"Privet\", \"therapist\": \"Hello! I'm here to support you. How can I help?\"},\n",
        "    {\"patient\": \"Zdravstvuyte\", \"therapist\": \"Hello! I'm here to listen. How are you feeling?\"},\n",
        "\n",
        "    # Thanks/Gratitude\n",
        "    {\"patient\": \"Thanks\", \"therapist\": \"You're welcome! Anything else I can help with?\"},\n",
        "    {\"patient\": \"Thank you\", \"therapist\": \"You're very welcome! I'm here if you need more support.\"},\n",
        "    {\"patient\": \"Thank you so much\", \"therapist\": \"My pleasure! Take care of yourself.\"},\n",
        "    {\"patient\": \"Thanks a lot\", \"therapist\": \"You're welcome! Feel free to reach out anytime.\"},\n",
        "    {\"patient\": \"Gracias\", \"therapist\": \"You're welcome! I'm here if you need me.\"},\n",
        "    {\"patient\": \"Merci\", \"therapist\": \"You're welcome! Take care.\"},\n",
        "    {\"patient\": \"Danke\", \"therapist\": \"You're welcome! I'm here to help anytime.\"},\n",
        "    {\"patient\": \"Grazie\", \"therapist\": \"You're welcome! Feel free to return anytime.\"},\n",
        "\n",
        "    # Goodbyes\n",
        "    {\"patient\": \"Bye\", \"therapist\": \"Take care! I'm here whenever you need support.\"},\n",
        "    {\"patient\": \"Goodbye\", \"therapist\": \"Goodbye! Reach out anytime you need to talk.\"},\n",
        "    {\"patient\": \"See you\", \"therapist\": \"Take care of yourself! I'm here if you need me.\"},\n",
        "    {\"patient\": \"See you later\", \"therapist\": \"See you! Remember, I'm here whenever you need support.\"},\n",
        "    {\"patient\": \"Take care\", \"therapist\": \"You too! Feel free to come back anytime.\"},\n",
        "    {\"patient\": \"Adiós\", \"therapist\": \"Take care! I'm here whenever you need me.\"},\n",
        "    {\"patient\": \"Au revoir\", \"therapist\": \"Goodbye! Reach out anytime.\"},\n",
        "    {\"patient\": \"Auf Wiedersehen\", \"therapist\": \"Take care! I'm here if you need support.\"},\n",
        "    {\"patient\": \"Arrivederci\", \"therapist\": \"Goodbye! Feel free to return anytime.\"},\n",
        "]\n",
        "\n",
        "greetings = greetings_base * 30  # 70 base greetings × 30 = 2,100 greeting examples\n",
        "\n",
        "print(f\" Added {len(greetings)} greeting examples (multilingual)\")\n",
        "\n",
        "# Process main dataset\n",
        "conversations = []\n",
        "for idx, row in df.iterrows():\n",
        "    if pd.notna(row['Context']) and pd.notna(row['Response']):\n",
        "        context = str(row['Context']).strip()\n",
        "        response = str(row['Response']).strip()\n",
        "        full_conversation = f\"Patient: {context}\\nTherapist: {response}\"\n",
        "        conversations.append({\n",
        "            'patient': context,\n",
        "            'therapist': response,\n",
        "            'full_conversation': full_conversation\n",
        "        })\n",
        "\n",
        "\n",
        "for greeting in greetings:\n",
        "    full_conversation = f\"Patient: {greeting['patient']}\\nTherapist: {greeting['therapist']}\"\n",
        "    conversations.insert(0, {\n",
        "        'patient': greeting['patient'],\n",
        "        'therapist': greeting['therapist'],\n",
        "        'full_conversation': full_conversation\n",
        "    })\n",
        "\n",
        "conv_df = pd.DataFrame(conversations)\n",
        "print(f\" Total conversations: {len(conv_df)}\")\n",
        "print(f\"   - Greetings: {len(greetings)}\")\n",
        "print(f\"   - Therapy conversations: {len(df)}\")\n",
        "\n",
        "# Save raw data\n",
        "conv_df.to_csv('data/raw/all_conversations.csv', index=False)\n",
        "print(\"Raw data saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "b423dadfac024f61bebdecb0174f1c87",
            "c91f69f8e59648e8aa62d717d8155a8c",
            "973239da71fa4e14a8f09e00499b84c8",
            "baf402d1c131463ca5de3ec7561dca35",
            "1203e30bdeeb4694aae65627459742dd",
            "c5f9e9bb686c416ca3016147fc1c5a4e",
            "e006554672c14bc484f0c218deb06694",
            "2cc4796b8d4048a39b0c4308db092deb",
            "e6a4d7018f5941f9982410e1c818225f",
            "05b1f19645d347fe8120262c009d995c",
            "3aaebedc034b403093d1d8419288e3a5",
            "281e72547e2b4ccdbddef8f6e2bccd8b",
            "21d0c558f0584d2ba8909e566d375429",
            "bdb59c98396546fe82beef55c5575bc9",
            "cb43c5fc2e2d4f8fbeb14a59fa8171c2",
            "c24f1a72e7d943d59a4c9ec16295c955",
            "c1b68ac5c5404657876bf91ba7e23e70",
            "b97c0a81a3eb4067b8200eac26c2bc21",
            "6405d5a4e3c444aea8ce7e3b05a9ebd6",
            "809b1f1eb9af43aeb8c6821b2c088420",
            "53f788a1cd5c41bdb6e7c6090f61f50c",
            "d81f7f6cc3954dcc9a6ac9c8874238dd",
            "578fc45de0bb4a5098464faaffac9460",
            "2e3622f1f87746d4ad94b790856c6227",
            "0f9973cbb2ba4cff86f36f2bcb0e2f22",
            "e9f1f12c3dfd4dc4ae827cfa848cbb36",
            "972393086a0f418e800f7bfd51716a5b",
            "0a8246754cc14821b4e7e58cb4dfee07",
            "28848b3daa4c46d6abf2fcccbbfe098c",
            "a317e92f6a2d42039f0bca1c12b492e9",
            "ec1f3d93c77748af9fd5eff5226c3073",
            "0439a64e011243559fcfc973e79166bf",
            "41ddc0379a444785b0560c2173fdbe6b"
          ]
        },
        "id": "nuJZo7C9qoZt",
        "outputId": "4fe890a7-36d8-45b0-fbb2-cffc745a25c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading mental health counseling dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b423dadfac024f61bebdecb0174f1c87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "combined_dataset.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "281e72547e2b4ccdbddef8f6e2bccd8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "578fc45de0bb4a5098464faaffac9460"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset loaded: 3512 conversations\n",
            " Added 1920 greeting examples (multilingual)\n",
            " Total conversations: 5432\n",
            "   - Greetings: 1920\n",
            "   - Therapy conversations: 3512\n",
            "Raw data saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split Data(preprocessing)**"
      ],
      "metadata": {
        "id": "pdTYVGXgq2Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = len(conv_df)\n",
        "print(f\"Total samples available: {total_samples}\")\n",
        "\n",
        "# Target 2000 training samples for extended training\n",
        "target_train_size = 2000\n",
        "\n",
        "if total_samples >= 2500:\n",
        "    # If we have enough data, use 2000 for training\n",
        "    train_size = min(target_train_size, int(total_samples * 0.8))\n",
        "    remaining = total_samples - train_size\n",
        "    val_size = remaining // 2\n",
        "    test_size = remaining - val_size\n",
        "\n",
        "    # First split: separate training data\n",
        "    train_df, temp_df = train_test_split(\n",
        "        conv_df,\n",
        "        train_size=train_size,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Second split: divide remaining into val and test\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=0.5,\n",
        "        random_state=42\n",
        "    )\n",
        "else:\n",
        "    # Fallback to percentage-based split for smaller datasets\n",
        "    train_df, temp_df = train_test_split(conv_df, test_size=0.2, random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training: {len(train_df)} samples\")\n",
        "print(f\"Validation: {len(val_df)} samples\")\n",
        "print(f\"Test: {len(test_df)} samples\")\n",
        "\n",
        "# Save splits\n",
        "train_df.to_csv('data/processed/train.csv', index=False)\n",
        "val_df.to_csv('data/processed/val.csv', index=False)\n",
        "test_df.to_csv('data/processed/test.csv', index=False)\n",
        "\n",
        "# Create text files with special tokens\n",
        "with open('data/processed/train.txt', 'w', encoding='utf-8') as f:\n",
        "    for conv in train_df['full_conversation']:\n",
        "        f.write(conv + '\\n<|endoftext|>\\n')\n",
        "\n",
        "with open('data/processed/val.txt', 'w', encoding='utf-8') as f:\n",
        "    for conv in val_df['full_conversation']:\n",
        "        f.write(conv + '\\n<|endoftext|>\\n')\n",
        "\n",
        "print(\"Data split completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN10RJdkq3lN",
        "outputId": "613a7791-80da-418d-a8dd-5309620d8ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples available: 5432\n",
            "Training: 2000 samples\n",
            "Validation: 1716 samples\n",
            "Test: 1716 samples\n",
            "Data split completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split Data(preprocessing)**"
      ],
      "metadata": {
        "id": "Ra_VkesxrOjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples = len(conv_df)\n",
        "print(f\"Total samples available: {total_samples}\")\n",
        "\n",
        "# Target 2000 training samples for extended training\n",
        "target_train_size = 2000\n",
        "\n",
        "if total_samples >= 2500:\n",
        "    # If we have enough data, use 2000 for training\n",
        "    train_size = min(target_train_size, int(total_samples * 0.8))\n",
        "    remaining = total_samples - train_size\n",
        "    val_size = remaining // 2\n",
        "    test_size = remaining - val_size\n",
        "\n",
        "    # First split: separate training data\n",
        "    train_df, temp_df = train_test_split(\n",
        "        conv_df,\n",
        "        train_size=train_size,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Second split: divide remaining into val and test\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df,\n",
        "        test_size=0.5,\n",
        "        random_state=42\n",
        "    )\n",
        "else:\n",
        "    # Fallback to percentage-based split for smaller datasets\n",
        "    train_df, temp_df = train_test_split(conv_df, test_size=0.2, random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training: {len(train_df)} samples\")\n",
        "print(f\"Validation: {len(val_df)} samples\")\n",
        "print(f\"Test: {len(test_df)} samples\")\n",
        "\n",
        "# Save splits\n",
        "train_df.to_csv('data/processed/train.csv', index=False)\n",
        "val_df.to_csv('data/processed/val.csv', index=False)\n",
        "test_df.to_csv('data/processed/test.csv', index=False)\n",
        "\n",
        "# Create text files with special tokens\n",
        "with open('data/processed/train.txt', 'w', encoding='utf-8') as f:\n",
        "    for conv in train_df['full_conversation']:\n",
        "        f.write(conv + '\\n<|endoftext|>\\n')\n",
        "\n",
        "with open('data/processed/val.txt', 'w', encoding='utf-8') as f:\n",
        "    for conv in val_df['full_conversation']:\n",
        "        f.write(conv + '\\n<|endoftext|>\\n')\n",
        "\n",
        "print(\"Data split completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6lUOhq0rPGe",
        "outputId": "6e0eeb9e-c999-446a-8108-16ae01c92687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples available: 5432\n",
            "Training: 2000 samples\n",
            "Validation: 1716 samples\n",
            "Test: 1716 samples\n",
            "Data split completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading GPT-2 Model**"
      ],
      "metadata": {
        "id": "gP_3cxcYrX9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Configure padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "print(f\" Model loaded: {model_name}\")\n",
        "print(f\"Parameters: {model.num_parameters():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "803acf953385459e98b37c6f3fabebcd",
            "f3e7833b165d4c6991189d2ce407c054",
            "bfca1daf2d3b458280ad69ef9818adba",
            "2fbac13aac8f4d2e99f42a5835f6e701",
            "ea6e39cd2af34b599b56d1e828652ab0",
            "d1fcc717db004fb694b8dcb579098108",
            "116b112f04b74e98954e84795c2de689",
            "e8f67d79edfa41a7b1c3c913ce610fea",
            "0388ea6d459c478796d02fe56ec79a6e",
            "386721e0bb85460eb3a4837c318aee04",
            "22669cbfbf8c471cafffd3a19e9f6cf8",
            "9c0c17c56883442994b34795fc8e69bc",
            "e17cfd7125014e6cb0dc3b2de6b5b34f",
            "6eff605738eb46d1a21ee2dc3653db67",
            "cebd480cf9504131b9bd5f022b44e6f2",
            "312b5db7987442a9a280712947dca033",
            "c80f213963c9425293dc340006e1909e",
            "cc629158f21a46e1bef8e7fc87f766ac",
            "1f22a1df77694bc59ac69475ac78c303",
            "200c323682c1484c9b3182199dc76662",
            "85c1b1f0905c4a51a6f265edc9e70189",
            "bb84707d198744dab25c6ca87c4591d5",
            "10b224155c524b15a59828abfba07e44",
            "2c9fb1f7671744baa1a4eb46a728a96f",
            "db787d4db36a40a68aad5211245f0bc4",
            "3bd01bd5a8a8423383ded1c5577d2f5a",
            "ec69cc86c4d14d30b000b608047000db",
            "05f7c9f35e334bd8a37901e4ce93c112",
            "a4de80ff52cc4b9890c70085113b5553",
            "8383efc5596e4081ad27503be1ddd40d",
            "e71d13e5ec9a4e18ad89a43f9a4cf04e",
            "1cca509b92e349f5bdb79250cef3ae49",
            "fda27a1bb29b4124b86c630c89239d62",
            "e6bd2337dc414255b3f7a831dbcd645e",
            "ab0fb2d1805d48af8049ebaca496f8a4",
            "a9f3d9abe9c149f79b9b08c1f4b55dab",
            "14bd3cdfecce4b70b03117c540597250",
            "754c2f5f6c93469989c598800313976a",
            "837ae373ef104221b9b2fdb2761888db",
            "db9370027be84d22bf1d20fea399997d",
            "d5c40949ea9e4ff2b761731a306afafe",
            "5510b7f4ccee4750b3cc7d75563200aa",
            "011d869f28ab4f33abff9230c1cfae82",
            "c3785e050ab94219b55e8cc4a20d1a0c",
            "ee83da514fcf46668240b7cfb5f8c8ee",
            "bc399a155a724f9e9f6e8dc9be303805",
            "1ad3d8e3b9014668bddc8a997142b086",
            "c3d6cce7c8a34674bad7c8f2d8cc392b",
            "1c51b71938e940d48733aab36d937ed3",
            "091c67fcb9774690a6542dafae415dab",
            "f4644b437827479e8e55a4f8c55777de",
            "038823b16c1c4fe4b6a6e7d9bfd2e271",
            "b713e52d84bc4a519acf6a7a2e2428d9",
            "c5c99a897ce14c488ae3c6a92536e523",
            "065d5e88bf374311a3f5714147334c63",
            "3dd596cca51946cda8c3da0210f072bc",
            "a39012f367094f95a97a2f09849cf4e5",
            "b31584e46548470085364b8757de3382",
            "c979883b4798447fbb73b1db685173ba",
            "c5481f5a92bf4a7890d364b187098502",
            "d59d30dc8ff2415db3e67e74fe961444",
            "c06ae43fe34b402f90d28aa8b441312c",
            "e97a6d1924e943c4914326ac35e7a1a4",
            "10c3ebb0c3c54b898cbcfd7676b388ae",
            "0ea9f8273883495aa8833d7de4106008",
            "86ef015aab69492093b78281ba3daa6b",
            "3f14e8239d9c41569c1a5f249f7faa1a",
            "d27e335de48d4f4896772939de10751c",
            "814d986a12404cef998c13b4ba097c4e",
            "4ff47decb8164f8eac7a0f3957cbe3c2",
            "e8c2d51fd19e49c59d0ddfc9668e2863",
            "3afa0ca7eec94eba9da21cc690cb772a",
            "c73113ab6e904728844491563bc47204",
            "b1e1911b2e5f42f681f3cb5f92563614",
            "1f20b89d6e1f4b2f80c60afd970e2af5",
            "a2f9718aa503471984b162ac7c717edd",
            "42721c8e85b1440390ebd989a9d8fca8"
          ]
        },
        "id": "A0RFQs0XrZPe",
        "outputId": "61b98a12-d8af-461d-d23b-9cf3d47eab54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "803acf953385459e98b37c6f3fabebcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c0c17c56883442994b34795fc8e69bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10b224155c524b15a59828abfba07e44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6bd2337dc414255b3f7a831dbcd645e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee83da514fcf46668240b7cfb5f8c8ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dd596cca51946cda8c3da0210f072bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f14e8239d9c41569c1a5f249f7faa1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model loaded: gpt2\n",
            "Parameters: 124,439,808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenizing Dataset**"
      ],
      "metadata": {
        "id": "_4TjvfZwrlQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=256, padding='max_length')\n",
        "\n",
        "# Load text data\n",
        "with open('data/processed/train.txt', 'r', encoding='utf-8') as f:\n",
        "    train_texts = [t.strip() for t in f.read().split('<|endoftext|>') if t.strip()]\n",
        "\n",
        "with open('data/processed/val.txt', 'r', encoding='utf-8') as f:\n",
        "    val_texts = [t.strip() for t in f.read().split('<|endoftext|>') if t.strip()]\n",
        "\n",
        "# Creating datasets\n",
        "train_dataset = Dataset.from_dict({'text': train_texts})\n",
        "val_dataset = Dataset.from_dict({'text': val_texts})\n",
        "\n",
        "# Tokenizing\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "12461aa1a77043008a1e1a8a6765c762",
            "f20387da72f5432db38213c849760e86",
            "99ad9adba2984d07a37cd021c33c47bd",
            "1a21591487b5400bb70dd3db65ae489f",
            "0ca6f48fbcc74c34abfecf0e73af1512",
            "2751263435fc4afebbf24b7d5b58f2d4",
            "5c8e516fd38343fcb493bba9b9f53e9b",
            "6260e861492141529c193296d551fa01",
            "53f48a9e26b942449561aa0545c0160c",
            "4f5b1aa7912a45029034d0a39f1c20a4",
            "05608c4c3dcf4d2d95a98e962febb86b",
            "368df31664d9414980f65f3c700b2b98",
            "62f3195480d346a1af1a8a4d50904d0b",
            "34fa7854967d4c6fa5ae454369f2abdc",
            "38dd77dbd5f84396b95c565f310f213e",
            "1020396e466a4fe3b19ac2970276a80b",
            "4faa7f82aac04fcb8a25f763c2561ad0",
            "62ca29f7bd2f4c6588c84af290cb1b92",
            "2a43b1091c5249769caff98a482038a0",
            "eb1e2dc58daf44dfacbc193b2e4775c0",
            "060d1bc36214473f88debd279478ff95",
            "cbe5e6d927ab4be9a2cc53d4811f51a8"
          ]
        },
        "id": "9JOnFM1brjNQ",
        "outputId": "88fc4042-46cd-445f-8042-d0805f4010bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12461aa1a77043008a1e1a8a6765c762"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1716 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "368df31664d9414980f65f3c700b2b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 2000\n",
            "Validation samples: 1716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='models/checkpoints',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=40,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='outputs/logs',\n",
        "    logging_steps=50,\n",
        "    eval_strategy='steps',\n",
        "    eval_steps=200,\n",
        "    save_steps=400,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "print(\"Extended training configuration set!\")\n",
        "print(f\"Total epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"Training samples: ~2000\")\n",
        "print(f\"Estimated training time: 1.5-2.5 hours with T4 GPU\")\n",
        "print(f\"Total training steps: ~{(2000 // 4 // 2) * 40}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NvHnu8iru27",
        "outputId": "87e0a931-01df-4ae2-f791-44b7b21f1f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extended training configuration set!\n",
            "Total epochs: 40\n",
            "Training samples: ~2000\n",
            "Estimated training time: 1.5-2.5 hours with T4 GPU\n",
            "Total training steps: ~10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "LvYEdfJ0rxfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Final training loss: {train_result.training_loss:.4f}\")\n",
        "\n",
        "# Save final model\n",
        "trainer.save_model('models/final_model')\n",
        "tokenizer.save_pretrained('models/tokenizer')\n",
        "\n",
        "# Save training metrics\n",
        "training_metrics = {\n",
        "    'training_loss': float(train_result.training_loss),\n",
        "    'training_time': str(train_result.metrics.get('train_runtime', 0)),\n",
        "    'epochs': training_args.num_train_epochs,\n",
        "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "with open('outputs/metrics/training_metrics.json', 'w') as f:\n",
        "    json.dump(training_metrics, f, indent=2)\n",
        "\n",
        "print(\" Model and metrics saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Do4PLuXarx8f",
        "outputId": "17b1b842-87e3-424c-f44e-2ae77121ec14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 1:18:52, Epoch 40/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.060200</td>\n",
              "      <td>2.889259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.883900</td>\n",
              "      <td>2.733809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.701500</td>\n",
              "      <td>2.628405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.596100</td>\n",
              "      <td>2.577521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.544800</td>\n",
              "      <td>2.531399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.462700</td>\n",
              "      <td>2.499451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>2.438000</td>\n",
              "      <td>2.469961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.358800</td>\n",
              "      <td>2.450100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.196000</td>\n",
              "      <td>2.436229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.252600</td>\n",
              "      <td>2.412402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>2.168100</td>\n",
              "      <td>2.391755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>2.126500</td>\n",
              "      <td>2.382178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>2.020000</td>\n",
              "      <td>2.376230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>1.952400</td>\n",
              "      <td>2.364216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.963300</td>\n",
              "      <td>2.348672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>2.340141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>1.941400</td>\n",
              "      <td>2.324087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>1.814700</td>\n",
              "      <td>2.321759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>1.810200</td>\n",
              "      <td>2.338237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.748900</td>\n",
              "      <td>2.311210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>1.747800</td>\n",
              "      <td>2.319997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>1.730500</td>\n",
              "      <td>2.318032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>1.632300</td>\n",
              "      <td>2.320816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>1.607100</td>\n",
              "      <td>2.315096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.657000</td>\n",
              "      <td>2.300854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>1.591600</td>\n",
              "      <td>2.316667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>1.540900</td>\n",
              "      <td>2.327543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>1.499300</td>\n",
              "      <td>2.315232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>1.506000</td>\n",
              "      <td>2.319455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>1.508700</td>\n",
              "      <td>2.309680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>1.505500</td>\n",
              "      <td>2.295738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>1.498100</td>\n",
              "      <td>2.308587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>1.489500</td>\n",
              "      <td>2.304037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>1.488000</td>\n",
              "      <td>2.319985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>1.412300</td>\n",
              "      <td>2.304313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>1.424700</td>\n",
              "      <td>2.322159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>1.400500</td>\n",
              "      <td>2.314785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>1.395900</td>\n",
              "      <td>2.307700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>1.373800</td>\n",
              "      <td>2.322650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>1.387800</td>\n",
              "      <td>2.300655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>1.400100</td>\n",
              "      <td>2.308199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>1.328200</td>\n",
              "      <td>2.314283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>1.314900</td>\n",
              "      <td>2.316575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>1.372300</td>\n",
              "      <td>2.319877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>1.361800</td>\n",
              "      <td>2.310026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>1.346400</td>\n",
              "      <td>2.307602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>1.325900</td>\n",
              "      <td>2.314091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>1.327300</td>\n",
              "      <td>2.312803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>1.325700</td>\n",
              "      <td>2.316046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>1.363400</td>\n",
              "      <td>2.317725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training completed!\n",
            "Final training loss: 1.7941\n",
            " Model and metrics saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating model...**"
      ],
      "metadata": {
        "id": "CzqwBoqJBh16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Evaluating model...\")\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"\\n Evaluation Metrics:\")\n",
        "print(f\"Validation Loss: {eval_results['eval_loss']:.4f}\")\n",
        "perplexity = np.exp(eval_results['eval_loss'])\n",
        "print(f\"Perplexity: {perplexity:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "eval_metrics = {\n",
        "    'eval_loss': float(eval_results['eval_loss']),\n",
        "    'perplexity': float(perplexity),\n",
        "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "with open('outputs/metrics/evaluation_metrics.json', 'w') as f:\n",
        "    json.dump(eval_metrics, f, indent=2)\n",
        "\n",
        "# Create detailed report\n",
        "report = f\"\"\"\n",
        "Mental Health Chatbot - Evaluation Report\n",
        "==========================================\n",
        "\n",
        "Training Configuration:\n",
        "- Epochs: {training_args.num_train_epochs}\n",
        "- Batch Size: {training_args.per_device_train_batch_size}\n",
        "- Learning Rate: {training_args.learning_rate}\n",
        "- Training Samples: {len(train_dataset)}\n",
        "\n",
        "Performance Metrics:\n",
        "- Validation Loss: {eval_results['eval_loss']:.4f}\n",
        "- Perplexity: {perplexity:.4f}\n",
        "- Training Loss: {train_result.training_loss:.4f}\n",
        "\n",
        "Model Information:\n",
        "- Base Model: GPT-2\n",
        "- Parameters: {model.num_parameters():,}\n",
        "- Domain: Mental Health Counseling\n",
        "\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "\n",
        "with open('outputs/evaluation_report.txt', 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"✅ Evaluation complete and saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "e_dp_MVXBizk",
        "outputId": "186978cb-af39-4ab9-c6a4-ab292be94e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='429' max='429' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [429/429 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluation Metrics:\n",
            "Validation Loss: 2.3112\n",
            "Perplexity: 10.0866\n",
            "✅ Evaluation complete and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Enhanced Chatbot with Fixed Greeting Responses**"
      ],
      "metadata": {
        "id": "zfCp5gcmBxHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading enhanced chatbot...\")\n",
        "\n",
        "generator = pipeline(\n",
        "    'text-generation',\n",
        "    model='models/final_model',\n",
        "    tokenizer='models/tokenizer',\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Hardcoded greeting responses (no model generation for greetings)\n",
        "GREETING_RESPONSES = {\n",
        "    # English\n",
        "    'hello': \"Hello! I'm here to support you. How can I help you today?\",\n",
        "    'hi': \"Hi! I'm your mental health support assistant. What's on your mind?\",\n",
        "    'hey': \"Hey! I'm here to listen. How are you feeling?\",\n",
        "    'good morning': \"Good morning! How can I support you today?\",\n",
        "    'good afternoon': \"Good afternoon! I'm here to help. What's going on?\",\n",
        "    'good evening': \"Good evening! How are you feeling today?\",\n",
        "    'good night': \"Good night! Is there something on your mind?\",\n",
        "    'how are you': \"I'm here for you. How are you doing?\",\n",
        "    'how are you doing': \"I'm well, thank you. How about you?\",\n",
        "    'what\\'s up': \"I'm here to help. What's on your mind?\",\n",
        "    'whats up': \"I'm here to help. What's on your mind?\",\n",
        "    'howdy': \"Hello! How can I support you today?\",\n",
        "    'greetings': \"Greetings! I'm here to listen. How are you?\",\n",
        "\n",
        "    # Spanish\n",
        "    'hola': \"Hola! I'm here to support you. How can I help?\",\n",
        "    'buenos días': \"Good morning! How are you feeling today?\",\n",
        "    'buenos dias': \"Good morning! How are you feeling today?\",\n",
        "    'buenas tardes': \"Good afternoon! I'm here to help. What's on your mind?\",\n",
        "    'buenas noches': \"Good evening! How can I support you?\",\n",
        "\n",
        "    # French\n",
        "    'bonjour': \"Bonjour! I'm here to support you. How can I help?\",\n",
        "    'salut': \"Hello! I'm here to listen. What's on your mind?\",\n",
        "    'bonsoir': \"Good evening! How are you feeling today?\",\n",
        "\n",
        "    # German\n",
        "    'hallo': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'guten morgen': \"Good morning! How are you feeling today?\",\n",
        "    'guten tag': \"Good day! I'm here to help. What's on your mind?\",\n",
        "    'guten abend': \"Good evening! How can I support you?\",\n",
        "\n",
        "    # Italian\n",
        "    'ciao': \"Ciao! I'm here to support you. How can I help?\",\n",
        "    'buongiorno': \"Good morning! How are you feeling today?\",\n",
        "    'buonasera': \"Good evening! I'm here to help. What's on your mind?\",\n",
        "\n",
        "    # Portuguese\n",
        "    'olá': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'ola': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'oi': \"Hi! I'm here to listen. What's on your mind?\",\n",
        "    'bom dia': \"Good morning! How are you feeling today?\",\n",
        "    'boa tarde': \"Good afternoon! How can I support you?\",\n",
        "    'boa noite': \"Good evening! I'm here to help. What's going on?\",\n",
        "\n",
        "    # Other languages\n",
        "    'namaste': \"Namaste! I'm here to support you. How can I help?\",\n",
        "    'namaskar': \"Hello! I'm here to listen. How are you feeling?\",\n",
        "    'marhaba': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'salam': \"Peace be with you. I'm here to listen. What's on your mind?\",\n",
        "    'konnichiwa': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'annyeong': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'privet': \"Hello! I'm here to support you. How can I help?\",\n",
        "\n",
        "    # Thanks\n",
        "    'thanks': \"You're welcome! Anything else I can help with?\",\n",
        "    'thank you': \"You're very welcome! I'm here if you need more support.\",\n",
        "    'thank you so much': \"My pleasure! Take care of yourself.\",\n",
        "    'thanks a lot': \"You're welcome! Feel free to reach out anytime.\",\n",
        "    'gracias': \"You're welcome! I'm here if you need me.\",\n",
        "    'merci': \"You're welcome! Take care.\",\n",
        "    'danke': \"You're welcome! I'm here to help anytime.\",\n",
        "    'grazie': \"You're welcome! Feel free to return anytime.\",\n",
        "\n",
        "    # Goodbyes\n",
        "    'bye': \"Take care! I'm here whenever you need support.\",\n",
        "    'goodbye': \"Goodbye! Reach out anytime you need to talk.\",\n",
        "    'see you': \"Take care of yourself! I'm here if you need me.\",\n",
        "    'see you later': \"See you! Remember, I'm here whenever you need support.\",\n",
        "    'take care': \"You too! Feel free to come back anytime.\",\n",
        "    'adiós': \"Take care! I'm here whenever you need me.\",\n",
        "    'adios': \"Take care! I'm here whenever you need me.\",\n",
        "    'au revoir': \"Goodbye! Reach out anytime.\",\n",
        "    'auf wiedersehen': \"Take care! I'm here if you need support.\",\n",
        "    'arrivederci': \"Goodbye! Feel free to return anytime.\",\n",
        "}\n",
        "\n",
        "# Mental health keywords for topic detection\n",
        "MENTAL_HEALTH_KEYWORDS = [\n",
        "    'feel', 'feeling', 'emotion', 'anxiety', 'stress', 'depression', 'sad', 'happy',\n",
        "    'worried', 'scared', 'angry', 'lonely', 'overwhelmed', 'tired', 'sleep', 'help',\n",
        "    'talk', 'listen', 'support', 'therapy', 'counseling', 'mental', 'health', 'mind',\n",
        "    'thought', 'thinking', 'mood', 'cope', 'coping', 'struggle', 'difficult', 'hard',\n",
        "    'problem', 'issue', 'concern', 'relationship', 'family', 'friend', 'work', 'life'\n",
        "]\n",
        "\n",
        "def is_greeting(query):\n",
        "    \"\"\"Check if query is a greeting\"\"\"\n",
        "    query_lower = query.lower().strip()\n",
        "    return query_lower in GREETING_RESPONSES\n",
        "\n",
        "def is_mental_health_related(query):\n",
        "    \"\"\"Check if query is related to mental health\"\"\"\n",
        "    query_lower = query.lower()\n",
        "    return any(keyword in query_lower for keyword in MENTAL_HEALTH_KEYWORDS)\n",
        "\n",
        "def chat(query, max_length=150):\n",
        "    \"\"\"Enhanced chat function with hardcoded greetings\"\"\"\n",
        "\n",
        "    query_clean = query.strip()\n",
        "\n",
        "    # Check if it's a greeting - return hardcoded response\n",
        "    if is_greeting(query_clean):\n",
        "        return GREETING_RESPONSES[query_clean.lower()]\n",
        "\n",
        "    # Check if query is mental health related\n",
        "    if not is_mental_health_related(query_clean):\n",
        "        return \"I'm a mental health support chatbot. I'm here to help with feelings, stress, anxiety, and emotional well-being. How are you feeling today?\"\n",
        "\n",
        "    # Generate response for mental health queries\n",
        "    prompt = f\"Patient: {query_clean}\\nTherapist:\"\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    full_text = response[0]['generated_text']\n",
        "\n",
        "    # Extract therapist response\n",
        "    if 'Therapist:' in full_text:\n",
        "        therapist_response = full_text.split('Therapist:')[1].strip()\n",
        "        if 'Patient:' in therapist_response:\n",
        "            therapist_response = therapist_response.split('Patient:')[0].strip()\n",
        "        return therapist_response\n",
        "\n",
        "    return full_text\n",
        "\n",
        "# Test with various queries\n",
        "test_queries = [\n",
        "    \"Hello\",\n",
        "    \"Hi\",\n",
        "    \"Good morning\",\n",
        "    \"Bonjour\",\n",
        "    \"Hola\",\n",
        "    \"I've been feeling really anxious lately\",\n",
        "    \"What's the weather like?\",  # this is Off-topic\n",
        "    \"I can't sleep at night\",\n",
        "    \"Who won the football game?\",  # this is  Off-topic\n",
        "    \"I feel overwhelmed\",\n",
        "    \"Thanks\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting Chatbot:\\n\")\n",
        "os.makedirs('outputs/samples', exist_ok=True)\n",
        "sample_conversations = []\n",
        "\n",
        "for query in test_queries:\n",
        "    response = chat(query)\n",
        "    conversation = f\"Patient: {query}\\nTherapist: {response}\\n\"\n",
        "    print(conversation)\n",
        "    print(\"-\" * 70)\n",
        "    sample_conversations.append(conversation)\n",
        "\n",
        "# Save sample conversations\n",
        "with open('outputs/samples/test_conversations.txt', 'w') as f:\n",
        "    f.write('\\n'.join(sample_conversations))\n",
        "\n",
        "print(\"Sample conversations saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPmPShwZB0bZ",
        "outputId": "96b9da3c-4828-40ef-b5ae-1cd2d81445df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading enhanced chatbot...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Chatbot:\n",
            "\n",
            "Patient: Hello\n",
            "Therapist: Hello! I'm here to support you. How can I help you today?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: Hi\n",
            "Therapist: Hi! I'm your mental health support assistant. What's on your mind?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: Good morning\n",
            "Therapist: Good morning! How can I support you today?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: Bonjour\n",
            "Therapist: Bonjour! I'm here to support you. How can I help?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: Hola\n",
            "Therapist: Hola! I'm here to support you. How can I help?\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: I've been feeling really anxious lately\n",
            "Therapist: I'm sorry to hear about your recent anxiety. Anxiety is a complex emotion that affects people, families, and workplaces. It's hard to be happy without having a lot of it. Anxiety is often linked to family dynamics, such as feeling down or without a secure place to go and feeling anxious about not being able to feel loved or accepted by your family or friends. Having said that, it's important to remember that anxiety is not a physical symptom of a mental health problem. It's a mental health symptom that we all deal with.  Anxiety can be debilitating and it's important that you are aware of the symptoms that you are experiencing.  In addition, be sure to seek professional help if you are experiencing any of the symptoms listed above.  Seek professional help right away if you are experiencing anxiety and it's likely that they will be able to help you manage them.  Anxiety is not something that can be managed alone. It takes a holistic approach that is designed to help you get through it all.  Take the time to talk with a local mental health professional about how you are feeling, if you have been experiencing anxiety and if you would like to discuss this with them.  I'm glad you are taking the time to connect with a mental health professional.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: What's the weather like?\n",
            "Therapist: I'm a mental health support chatbot. I'm here to help with feelings, stress, anxiety, and emotional well-being. How are you feeling today?\n",
            "\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient: I can't sleep at night\n",
            "Therapist: You're not alone! If you're feeling like you need help, talk to a local mental health professional. They can help you figure out if you may be experiencing any of the following symptoms:Feeling tired - Sometimes we don't sleep well enough for our bodies to make sleep, and sometimes we sleep too much and sometimes we don't sleep enough.  Sometimes we can wake up and feel tired but also can't sleep because we're not used to sleeping.  Sometimes we can't sleep because of stress, or because we're not used to being around people.  If you've been diagnosed with sleep disorders, talk to a local mental health professional to discuss them with them.  Sometimes stress is a sign of a problem, and some medications can help to reduce it.  Talk to your doctor about what's causing the symptoms, and what steps you can take to help reduce them.  It's also important to talk with a mental health professional about whether you have the symptoms.  If you feel like you have the symptoms, talk to your doctor about them.  It's also important to talk with a mental health professional about whether you have the symptoms.  Sometimes stress is a sign of a problem, and some medications\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: Who won the football game?\n",
            "Therapist: I'm a mental health support chatbot. I'm here to help with feelings, stress, anxiety, and emotional well-being. How are you feeling today?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: I feel overwhelmed\n",
            "Therapist: I'm here to listen. What's on your mind?  What's on your mind?  What's on your mind?   What's on your mind?  What's on your mind?    Tell me about yourself.  What's on your mind?  What's on your mind?   Tell me about yourself.  How can I help?  What's on your mind?   Tell me about yourself.  What are you looking for in a therapist?  What can I do to get you started?  What can I do to make you feel more at ease?  What are you looking for in a counselor?  What can I do to get you started?  What can I do to make you feel more comfortable?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Patient: Thanks\n",
            "Therapist: You're welcome! Anything else I can help with?\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Sample conversations saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Enhanced Gradio Interface**"
      ],
      "metadata": {
        "id": "wVPxV7EYB9Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "GREETING_RESPONSES = {\n",
        "    'hello': \"Hello! I'm here to support you. How can I help you today?\",\n",
        "    'hi': \"Hi! I'm your mental health support assistant. What's on your mind?\",\n",
        "    'hey': \"Hey! I'm here to listen. How are you feeling?\",\n",
        "    'good morning': \"Good morning! How can I support you today?\",\n",
        "    'good afternoon': \"Good afternoon! I'm here to help. What's going on?\",\n",
        "    'good evening': \"Good evening! How are you feeling today?\",\n",
        "    'good night': \"Good night! Is there something on your mind?\",\n",
        "    'how are you': \"I'm here for you. How are you doing?\",\n",
        "    'how are you doing': \"I'm well, thank you. How about you?\",\n",
        "    'what\\'s up': \"I'm here to help. What's on your mind?\",\n",
        "    'whats up': \"I'm here to help. What's on your mind?\",\n",
        "    'howdy': \"Hello! How can I support you today?\",\n",
        "    'greetings': \"Greetings! I'm here to listen. How are you?\",\n",
        "    'hola': \"Hola! I'm here to support you. How can I help?\",\n",
        "    'buenos días': \"Good morning! How are you feeling today?\",\n",
        "    'buenos dias': \"Good morning! How are you feeling today?\",\n",
        "    'buenas tardes': \"Good afternoon! I'm here to help. What's on your mind?\",\n",
        "    'buenas noches': \"Good evening! How can I support you?\",\n",
        "    'bonjour': \"Bonjour! I'm here to support you. How can I help?\",\n",
        "    'salut': \"Hello! I'm here to listen. What's on your mind?\",\n",
        "    'bonsoir': \"Good evening! How are you feeling today?\",\n",
        "    'hallo': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'guten morgen': \"Good morning! How are you feeling today?\",\n",
        "    'guten tag': \"Good day! I'm here to help. What's on your mind?\",\n",
        "    'guten abend': \"Good evening! How can I support you?\",\n",
        "    'ciao': \"Ciao! I'm here to support you. How can I help?\",\n",
        "    'buongiorno': \"Good morning! How are you feeling today?\",\n",
        "    'buonasera': \"Good evening! I'm here to help. What's on your mind?\",\n",
        "    'olá': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'ola': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'oi': \"Hi! I'm here to listen. What's on your mind?\",\n",
        "    'bom dia': \"Good morning! How are you feeling today?\",\n",
        "    'boa tarde': \"Good afternoon! How can I support you?\",\n",
        "    'boa noite': \"Good evening! I'm here to help. What's going on?\",\n",
        "    'namaste': \"Namaste! I'm here to support you. How can I help?\",\n",
        "    'namaskar': \"Hello! I'm here to listen. How are you feeling?\",\n",
        "    'marhaba': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'salam': \"Peace be with you. I'm here to listen. What's on your mind?\",\n",
        "    'konnichiwa': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'ohayou': \"Good morning! How are you feeling today?\",\n",
        "    'annyeong': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'privet': \"Hello! I'm here to support you. How can I help?\",\n",
        "    'thanks': \"You're welcome! Anything else I can help with?\",\n",
        "    'thank you': \"You're very welcome! I'm here if you need more support.\",\n",
        "    'thank you so much': \"My pleasure! Take care of yourself.\",\n",
        "    'thanks a lot': \"You're welcome! Feel free to reach out anytime.\",\n",
        "    'gracias': \"You're welcome! I'm here if you need me.\",\n",
        "    'merci': \"You're welcome! Take care.\",\n",
        "    'danke': \"You're welcome! I'm here to help anytime.\",\n",
        "    'grazie': \"You're welcome! Feel free to return anytime.\",\n",
        "    'bye': \"Take care! I'm here whenever you need support.\",\n",
        "    'goodbye': \"Goodbye! Reach out anytime you need to talk.\",\n",
        "    'see you': \"Take care of yourself! I'm here if you need me.\",\n",
        "    'see you later': \"See you! Remember, I'm here whenever you need support.\",\n",
        "    'take care': \"You too! Feel free to come back anytime.\",\n",
        "    'adiós': \"Take care! I'm here whenever you need me.\",\n",
        "    'adios': \"Take care! I'm here whenever you need me.\",\n",
        "    'au revoir': \"Goodbye! Reach out anytime.\",\n",
        "    'auf wiedersehen': \"Take care! I'm here if you need support.\",\n",
        "    'arrivederci': \"Goodbye! Feel free to return anytime.\",\n",
        "}\n",
        "\n",
        "# Follow-up responses after greetings (context-aware)\n",
        "FOLLOWUP_RESPONSES = {\n",
        "    # Positive responses\n",
        "    'i am good': \"That's wonderful to hear! I'm glad you're doing well. Is there anything specific you'd like to talk about today?\",\n",
        "    'im good': \"That's great! I'm happy to hear that. How can I support you today?\",\n",
        "    'i\\'m good': \"That's great! I'm happy to hear that. How can I support you today?\",\n",
        "    'good': \"Nice to hear! What brings you here today?\",\n",
        "    'great': \"That's fantastic! How can I help you today?\",\n",
        "    'fine': \"Good to know! Is there something on your mind you'd like to discuss?\",\n",
        "    'okay': \"Alright! What would you like to talk about?\",\n",
        "    'ok': \"Alright! What would you like to talk about?\",\n",
        "    'well': \"Good! How can I assist you today?\",\n",
        "    'doing well': \"That's wonderful! What can I help you with?\",\n",
        "    'doing good': \"That's great to hear! How can I support you?\",\n",
        "    'pretty good': \"Glad to hear that! What's on your mind?\",\n",
        "\n",
        "    # Negative/struggling responses\n",
        "    'not good': \"I'm sorry to hear that. Would you like to share what's troubling you?\",\n",
        "    'not well': \"I'm here to listen. What's been going on?\",\n",
        "    'bad': \"I'm sorry you're feeling this way. Can you tell me more about what's happening?\",\n",
        "    'terrible': \"I'm really sorry you're going through this. I'm here to support you. What's been troubling you?\",\n",
        "    'awful': \"That sounds really difficult. I'm here to listen. What's going on?\",\n",
        "    'horrible': \"I'm sorry you're feeling this way. Would you like to talk about it?\",\n",
        "    'not great': \"I understand. What's been bothering you?\",\n",
        "    'could be better': \"I hear you. What's on your mind?\",\n",
        "    'struggling': \"I'm here for you. What are you struggling with?\",\n",
        "    'difficult': \"I'm sorry things are difficult right now. How can I help?\",\n",
        "    'hard': \"I understand it's been hard. Would you like to share more?\",\n",
        "    'tough': \"I'm here to support you through tough times. What's going on?\",\n",
        "}\n",
        "\n",
        "# Comprehensive mental health keywords (expanded from dataset)\n",
        "MENTAL_HEALTH_KEYWORDS = [\n",
        "    # Emotions & Feelings\n",
        "    'feel', 'feeling', 'feelings', 'felt', 'emotion', 'emotional', 'emotions',\n",
        "    'mood', 'moods', 'sad', 'sadness', 'happy', 'happiness', 'joy', 'joyful',\n",
        "    'angry', 'anger', 'mad', 'frustrated', 'frustration', 'irritated',\n",
        "    'scared', 'fear', 'afraid', 'frightened', 'terrified', 'panic',\n",
        "    'worried', 'worry', 'worrying', 'concern', 'concerned', 'nervous',\n",
        "    'lonely', 'loneliness', 'alone', 'isolated', 'isolation',\n",
        "    'overwhelmed', 'overwhelming', 'stressed', 'stress', 'pressure',\n",
        "    'hopeless', 'helpless', 'worthless', 'guilty', 'guilt', 'shame',\n",
        "    'hurt', 'pain', 'painful', 'suffering', 'ache', 'aching',\n",
        "\n",
        "    # Mental Health Conditions\n",
        "    'anxiety', 'anxious', 'panic attack', 'panic attacks', 'worried',\n",
        "    'depression', 'depressed', 'depressing', 'down', 'low',\n",
        "    'ptsd', 'trauma', 'traumatic', 'traumatized',\n",
        "    'ocd', 'obsessive', 'compulsive',\n",
        "    'bipolar', 'manic', 'mania',\n",
        "    'adhd', 'attention', 'focus', 'concentrate', 'concentration',\n",
        "\n",
        "    # Physical symptoms related to mental health\n",
        "    'tired', 'exhausted', 'fatigue', 'energy', 'sleep', 'sleeping',\n",
        "    'insomnia', 'nightmare', 'nightmares', 'cant sleep', 'can\\'t sleep',\n",
        "    'appetite', 'eating', 'weight', 'headache', 'headaches',\n",
        "\n",
        "    # Thoughts & Cognition\n",
        "    'thought', 'thoughts', 'thinking', 'think', 'mind', 'mental',\n",
        "    'remember', 'memory', 'memories', 'forget', 'forgetting',\n",
        "    'confused', 'confusion', 'clarity', 'clear',\n",
        "    'suicidal', 'suicide', 'self harm', 'self-harm', 'hurt myself',\n",
        "\n",
        "    # Coping & Support\n",
        "    'cope', 'coping', 'deal', 'dealing', 'handle', 'handling', 'manage',\n",
        "    'help', 'support', 'need', 'struggle', 'struggling', 'difficult',\n",
        "    'hard', 'tough', 'challenge', 'challenging', 'problem', 'problems',\n",
        "    'issue', 'issues', 'trouble', 'crisis',\n",
        "\n",
        "    # Therapy & Treatment\n",
        "    'therapy', 'therapist', 'counseling', 'counselor', 'psychologist',\n",
        "    'psychiatrist', 'medication', 'medicine', 'treatment', 'doctor',\n",
        "\n",
        "    # Relationships & Social\n",
        "    'relationship', 'relationships', 'partner', 'spouse', 'marriage',\n",
        "    'family', 'parent', 'parents', 'mother', 'father', 'mom', 'dad',\n",
        "    'friend', 'friends', 'friendship', 'social', 'people',\n",
        "    'breakup', 'break up', 'divorce', 'separated', 'conflict',\n",
        "\n",
        "    # Life situations\n",
        "    'work', 'job', 'career', 'school', 'college', 'university',\n",
        "    'money', 'financial', 'finances', 'debt',\n",
        "    'abuse', 'abusive', 'violence', 'violent',\n",
        "    'loss', 'grief', 'grieving', 'death', 'died',\n",
        "    'change', 'changes', 'transition', 'moving',\n",
        "\n",
        "    # Positive mental health\n",
        "    'better', 'improve', 'improvement', 'progress', 'growth',\n",
        "    'heal', 'healing', 'recover', 'recovery', 'hope', 'hopeful',\n",
        "    'strength', 'strong', 'resilient', 'resilience',\n",
        "\n",
        "    # Negative states\n",
        "    'not good', 'not well', 'bad', 'terrible', 'awful', 'horrible',\n",
        "    'worse', 'worst', 'crisis', 'emergency', 'urgent',\n",
        "]\n",
        "\n",
        "# Conversation context tracker\n",
        "conversation_context = {'last_was_greeting': False}\n",
        "\n",
        "def is_greeting(query):\n",
        "    return query.lower().strip() in GREETING_RESPONSES\n",
        "\n",
        "def is_followup(query):\n",
        "    return query.lower().strip() in FOLLOWUP_RESPONSES\n",
        "\n",
        "def is_mental_health_related(query):\n",
        "    return any(keyword in query.lower() for keyword in MENTAL_HEALTH_KEYWORDS)\n",
        "\n",
        "def get_bot_response(message):\n",
        "    \"\"\"Get bot response with context awareness\"\"\"\n",
        "    message_clean = message.strip()\n",
        "\n",
        "    if not message_clean:\n",
        "        return \"\"\n",
        "\n",
        "    # Check if it's a greeting\n",
        "    if is_greeting(message_clean):\n",
        "        conversation_context['last_was_greeting'] = True\n",
        "        return GREETING_RESPONSES[message_clean.lower()]\n",
        "\n",
        "    # Check if it's a follow-up after greeting\n",
        "    if conversation_context['last_was_greeting'] and is_followup(message_clean):\n",
        "        conversation_context['last_was_greeting'] = False\n",
        "        return FOLLOWUP_RESPONSES[message_clean.lower()]\n",
        "\n",
        "    # Reset greeting context for other messages\n",
        "    conversation_context['last_was_greeting'] = False\n",
        "\n",
        "    # Off-topic detection\n",
        "    if not is_mental_health_related(message_clean):\n",
        "        return \"I'm a mental health support chatbot. I'm here to help with feelings, stress, anxiety, and emotional well-being. How are you feeling today?\"\n",
        "\n",
        "    # Generate response for mental health queries\n",
        "    prompt = f\"Patient: {message_clean}\\nTherapist:\"\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    full_text = response[0]['generated_text']\n",
        "\n",
        "    if 'Therapist:' in full_text:\n",
        "        therapist_response = full_text.split('Therapist:')[1].strip()\n",
        "        if 'Patient:' in therapist_response:\n",
        "            therapist_response = therapist_response.split('Patient:')[0].strip()\n",
        "        return therapist_response\n",
        "\n",
        "    return full_text\n",
        "\n",
        "def chat_function_with_typing(message, history):\n",
        "    \"\"\"Process message with typing animation effect\"\"\"\n",
        "    if not message.strip():\n",
        "        yield history, \"\"\n",
        "        return\n",
        "\n",
        "    # Get bot response\n",
        "    bot_response = get_bot_response(message)\n",
        "\n",
        "    # Add user message to history\n",
        "    history.append((message, \"\"))\n",
        "\n",
        "    # Simulate typing effect - stream response word by word\n",
        "    words = bot_response.split()\n",
        "    displayed_response = \"\"\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        displayed_response += word + \" \"\n",
        "        history[-1] = (message, displayed_response.strip())\n",
        "        yield history, \"\"\n",
        "        time.sleep(0.05)  # Adjust speed of typing (0.05 seconds per word)\n",
        "\n",
        "    # Final complete response\n",
        "    history[-1] = (message, bot_response)\n",
        "    yield history, \"\"\n",
        "\n",
        "def clear_input():\n",
        "    \"\"\"Clear the input textbox\"\"\"\n",
        "    return \"\"\n",
        "\n",
        "def new_chat():\n",
        "    \"\"\"Start a new chat by clearing history and context\"\"\"\n",
        "    conversation_context['last_was_greeting'] = False\n",
        "    return [], \"\"\n",
        "\n",
        "# Custom CSS for beautiful animated design\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    max-width: 900px !important;\n",
        "    margin: auto !important;\n",
        "}\n",
        "\n",
        "#chatbot {\n",
        "    height: 500px;\n",
        "    border-radius: 12px;\n",
        "    box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);\n",
        "}\n",
        "\n",
        ".message {\n",
        "    animation: fadeIn 0.3s ease-in;\n",
        "}\n",
        "\n",
        "@keyframes fadeIn {\n",
        "    from { opacity: 0; transform: translateY(10px); }\n",
        "    to { opacity: 1; transform: translateY(0); }\n",
        "}\n",
        "\n",
        ".header-box {\n",
        "    text-align: center;\n",
        "    padding: 25px;\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "    border-radius: 15px;\n",
        "    color: white;\n",
        "    margin-bottom: 20px;\n",
        "    box-shadow: 0 8px 32px rgba(0,0,0,0.1);\n",
        "    animation: slideDown 0.5s ease-out;\n",
        "}\n",
        "\n",
        "@keyframes slideDown {\n",
        "    from { opacity: 0; transform: translateY(-20px); }\n",
        "    to { opacity: 1; transform: translateY(0); }\n",
        "}\n",
        "\n",
        ".bot-message {\n",
        "    background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);\n",
        "    border-left: 3px solid #667eea;\n",
        "    padding: 12px;\n",
        "    border-radius: 8px;\n",
        "    animation: slideIn 0.3s ease-out;\n",
        "}\n",
        "\n",
        "@keyframes slideIn {\n",
        "    from { opacity: 0; transform: translateX(-10px); }\n",
        "    to { opacity: 1; transform: translateX(0); }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Create custom Gradio interface with Blocks\n",
        "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"purple\", secondary_hue=\"pink\"), css=custom_css) as demo:\n",
        "\n",
        "    # Header\n",
        "    gr.HTML(\"\"\"\n",
        "        <div class=\"header-box\">\n",
        "            <h1 style='margin: 0; font-size: 32px; font-weight: 700;'>💙 Mental Health Support Chatbot</h1>\n",
        "            <p style='margin: 15px 0 0 0; font-size: 17px; opacity: 0.95; line-height: 1.6;'>\n",
        "                I'm here to provide emotional support and listen to your concerns.<br/>\n",
        "                Share your thoughts and feelings in a safe, judgment-free space.\n",
        "            </p>\n",
        "        </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # Chatbot display\n",
        "    chatbot = gr.Chatbot(\n",
        "        value=[],\n",
        "        elem_id=\"chatbot\",\n",
        "        height=500,\n",
        "        show_label=False,\n",
        "        elem_classes=\"bot-message\"\n",
        "    )\n",
        "\n",
        "    # Input row with textbox and buttons\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Share your thoughts and feelings here...\",\n",
        "            show_label=False,\n",
        "            scale=7,\n",
        "            lines=2,\n",
        "            max_lines=4\n",
        "        )\n",
        "        send_btn = gr.Button(\"💬 Send\", variant=\"primary\", scale=1)\n",
        "\n",
        "    # Action buttons row\n",
        "    with gr.Row():\n",
        "        clear_input_btn = gr.Button(\"🗑️ Clear Input\", variant=\"secondary\", size=\"sm\")\n",
        "        new_chat_btn = gr.Button(\"✨ New Chat\", variant=\"secondary\", size=\"sm\")\n",
        "\n",
        "    # Example prompts\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"I am stressed out \",\n",
        "            \"I've been feeling anxious lately\",\n",
        "        ],\n",
        "        inputs=msg,\n",
        "        label=\"💡 Try these examples:\"\n",
        "    )\n",
        "\n",
        "    # Event handlers with typing animation\n",
        "    msg.submit(chat_function_with_typing, [msg, chatbot], [chatbot, msg])\n",
        "    send_btn.click(chat_function_with_typing, [msg, chatbot], [chatbot, msg])\n",
        "    clear_input_btn.click(clear_input, None, msg)\n",
        "    new_chat_btn.click(new_chat, None, [chatbot, msg])\n",
        "\n",
        "# Launch with public link\n",
        "print(\"✨ Launching beautiful mental health chatbot interface...\")\n",
        "print(\"🌐 Creating public shareable link...\")\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True,\n",
        "    show_error=True\n",
        ")\n",
        "print(\"\\n✅ Chatbot is live!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "R3ZPUyU3B7wc",
        "outputId": "8bc88d25-7451-48ac-8544-a2b2a84e3622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨ Launching beautiful mental health chatbot interface...\n",
            "🌐 Creating public shareable link...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b89ff3f83cf18bac0b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b89ff3f83cf18bac0b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b89ff3f83cf18bac0b.gradio.live\n",
            "\n",
            "✅ Chatbot is live!\n"
          ]
        }
      ]
    }
  ]
}
